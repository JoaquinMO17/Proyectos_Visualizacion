# üéØ ETL Performance Benchmarking Guide

Esta gu√≠a explica c√≥mo usar el sistema de benchmarking para analizar el rendimiento del pipeline ETL de pel√≠culas IMDB.

## üìã Resumen del Sistema

El sistema de benchmarking mide:
- ‚è±Ô∏è **Tiempo de procesamiento** (total y por fase)
- üíæ **Uso de memoria** (RAM, picos, eficiencia)
- üñ•Ô∏è **Utilizaci√≥n de CPU** (promedio, m√°ximo)
- üìÅ **Generaci√≥n de archivos** (tama√±os, throughput)
- üöÄ **Throughput** (registros/segundo, MB/segundo)

## üöÄ Inicio R√°pido

### 1. Benchmark B√°sico (Dataset Completo)
```powershell
# Ejecutar benchmark del ETL completo (85,736 pel√≠culas)
.\run_benchmark_etl.ps1
```

**Salida esperada:**
- `benchmark_results.json` - M√©tricas detalladas
- `BENCHMARK_REPORT.md` - Reporte completo
- `benchmark_charts.png` - Gr√°ficas de rendimiento

### 2. Benchmark Avanzado (Monitoreo en Tiempo Real)
```powershell
# Para an√°lisis m√°s detallado con monitoreo continuo
docker-compose run --rm web python advanced_benchmark.py
```

**Salida adicional:**
- `advanced_benchmark_results.json` - M√©tricas avanzadas
- `monitoring_data.csv` - Datos de monitoreo segundo a segundo

### 3. Benchmark de Escalabilidad
```powershell
# Crear datasets de prueba peque√±os
docker-compose run --rm web python create_test_datasets.py

# Ejecutar benchmarks en m√∫ltiples tama√±os
.\run_scalability_benchmark.ps1
```

## üìä Interpretaci√≥n de Resultados

### M√©tricas Clave

| M√©trica | Descripci√≥n | Valor T√≠pico |
|---------|-------------|--------------|
| **Records/Second** | Velocidad de procesamiento | 100-200 rps |
| **Peak Memory (MB)** | M√°ximo uso de memoria | 200-500 MB |
| **Memory Delta (MB)** | Memoria adicional usada | 50-200 MB |
| **Memory Efficiency** | MB por 1,000 registros | 1-5 MB/1K |
| **Processing Time** | Tiempo total de ETL | 5-15 minutos |

### Interpretaci√≥n de Performance

#### ‚úÖ **Excelente Performance**
- Records/Second: >150
- Memory Efficiency: <3 MB/1K records
- Processing Time: <10 minutos

#### ‚ö†Ô∏è **Performance Aceptable**
- Records/Second: 50-150
- Memory Efficiency: 3-7 MB/1K records
- Processing Time: 10-20 minutos

#### ‚ùå **Performance Necesita Optimizaci√≥n**
- Records/Second: <50
- Memory Efficiency: >7 MB/1K records
- Processing Time: >20 minutos

## üìÅ Archivos del Sistema

### Scripts de Ejecuci√≥n
- `run_benchmark_etl.ps1` - Benchmark principal
- `run_scalability_benchmark.ps1` - Pruebas de escalabilidad

### Scripts de Python
- `benchmark_etl.py` - Benchmark b√°sico
- `advanced_benchmark.py` - Benchmark con monitoreo en tiempo real
- `benchmark_utils.py` - Generaci√≥n de reportes y gr√°ficas
- `create_test_datasets.py` - Generador de datasets de prueba

### Archivos de Resultados
- `benchmark_results.json` - Resultados b√°sicos
- `advanced_benchmark_results.json` - Resultados avanzados
- `BENCHMARK_REPORT.md` - Reporte detallado
- `benchmark_charts.png` - Visualizaciones
- `monitoring_data.csv` - Datos de monitoreo continuo

## üîß Configuraci√≥n de Pruebas

### Tama√±os de Dataset Disponibles
- **Small**: 1,000 registros (~1 MB)
- **Medium**: 5,000 registros (~5 MB)
- **Large**: 10,000 registros (~10 MB)
- **XLarge**: 25,000 registros (~25 MB)
- **Full**: 85,736 registros (~42 MB)

### Personalizar Benchmark

Para crear un benchmark personalizado:

```python
from benchmark_etl import ETLBenchmark

# Crear instancia de benchmark
benchmark = ETLBenchmark()

# Ejecutar con monitoreo personalizado
benchmark.run_full_benchmark()

# Acceder a resultados
results = benchmark.results
print(f"Procesados: {results['total_records']} registros")
print(f"Tiempo: {results['total_duration_minutes']:.2f} minutos")
```

## üìä An√°lisis de Bottlenecks

### Identificar Problemas de Performance

#### 1. **Memory Bottlenecks**
- **S√≠ntoma**: Memory Delta >500 MB
- **Causa**: Cargar todo el dataset en memoria
- **Soluci√≥n**: Implementar procesamiento por chunks

#### 2. **CPU Bottlenecks**
- **S√≠ntoma**: CPU >90% por per√≠odos largos
- **Causa**: Transformaciones complejas
- **Soluci√≥n**: Optimizar funciones de transformaci√≥n

#### 3. **I/O Bottlenecks**
- **S√≠ntoma**: Records/Second <50
- **Causa**: Muchas operaciones de disco
- **Soluci√≥n**: Batch processing, escritura en memoria

#### 4. **Database Bottlenecks**
- **S√≠ntoma**: Fase de Load muy lenta
- **Causa**: Inserciones individuales
- **Soluci√≥n**: Bulk inserts, transacciones por lotes

## üéØ Mejores Pr√°cticas

### Para Obtener Resultados Consistentes
1. **Cerrar aplicaciones innecesarias** antes del benchmark
2. **Ejecutar m√∫ltiples veces** y promediar resultados
3. **Usar el mismo hardware** para comparaciones
4. **Reiniciar servicios Docker** entre pruebas

### Para Presentations del Equipo
1. **Usar gr√°ficas** (`benchmark_charts.png`)
2. **Mostrar m√©tricas clave** (Records/Second, Memory Efficiency)
3. **Comparar con benchmarks** de la industria
4. **Explicar optimizaciones** implementadas

## üîç Troubleshooting

### Problemas Comunes

#### Error: "psutil not found"
```bash
# Instalar dependencias
pip install psutil matplotlib
```

#### Error: "Docker not running"
```powershell
# Verificar Docker
docker info
# Iniciar servicios si es necesario
docker-compose up -d
```

#### Error: "Benchmark results not found"
- Verificar que el ETL complet√≥ exitosamente
- Revisar logs de Docker para errores
- Verificar permisos de escritura de archivos

#### Performance Inesperadamente Baja
- Verificar recursos disponibles del sistema
- Cerrar aplicaciones que consumen CPU/memoria
- Verificar que no hay otros containers ejecut√°ndose

## üìà Benchmarks de la Industria

### Comparaci√≥n con Est√°ndares ETL

| Tipo de ETL | Records/Second | Memory/1K Records |
|-------------|----------------|-------------------|
| **ETL Simple** | 500-1000 | 0.5-2 MB |
| **ETL Complejo** | 100-500 | 2-10 MB |
| **ETL Enterprise** | 50-200 | 5-20 MB |
| **Nuestro ETL** | **100-200** | **2-5 MB** |

### Factores que Afectan Performance
- **Complejidad de transformaciones**
- **Tama√±o del dataset**
- **Tipo de base de datos**
- **Recursos de hardware**
- **Configuraci√≥n de red**

## üí° Optimizaciones Recomendadas

### Para Mejorar Throughput
1. **Incrementar batch size** en cargas
2. **Usar conexiones paralelas** a DB
3. **Optimizar queries SQL**
4. **Implementar caching** de resultados

### Para Reducir Memoria
1. **Procesamiento por chunks**
2. **Liberar DataFrames** despu√©s de uso
3. **Usar generadores** en lugar de listas
4. **Optimizar tipos de datos** en pandas

### Para Reducir Tiempo
1. **Procesamiento paralelo** de archivos
2. **Eliminar validaciones** innecesarias
3. **Usar formato binario** (parquet vs CSV)
4. **Optimizar I/O** con SSD

## üìû Soporte

Para dudas sobre el sistema de benchmarking:
1. Revisar logs en `logs/etl.log`
2. Verificar `benchmark_results.json` para detalles
3. Consultar este documento para troubleshooting
4. Revisar configuraci√≥n de Docker y base de datos

---

**Sistema desarrollado para proyecto de Visualizaci√≥n de Datos**
*√öltima actualizaci√≥n: Septiembre 2025*